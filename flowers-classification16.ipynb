{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport os\nimport pickle\n\nfrom keras import optimizer_v1\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D, Dropout, Flatten, Dense, BatchNormalization, Activation, GlobalAveragePooling2D\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import Model, regularizers, layers, backend\nfrom PIL import Image\n\nprint(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\nexcept ValueError:\n    tpu = None\n\n# TPUStrategy for distributed training\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse: # default strategy that works on CPU and single GPU\n    strategy = tf.distribute.get_strategy()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"flowers = [\"bougainvillea\", \"daisy\", \"dandelion\", \"gardenia\", \"hibiscus\", \"hydrangea\",\n          \"iris\", \"lily\", \"lotus\", \"morningglory\", \"peachflower\",\"peony\", \"phalaenopsis\",\n           \"rose\", \"sunflower\", \"tulip\"]\n\nroot_path = '../input/flowers-16classes/'\n\ndef readImg(root_path):\n    x = []\n    y = []\n    for i, flower in enumerate(flowers):\n        train_folder_path = root_path + flower  # 通过字典拼接文件夹路径\n        for root, dirs, files in os.walk(train_folder_path):\n            for file in files:\n                img_path = train_folder_path + \"/\" + file  # 拼接图片路径\n                img = Image.open(img_path)  # 读入图片\n                img = img.convert(\"RGB\")\n                img = img.resize((224, 224), Image.ANTIALIAS)\n                img_arr = np.array(img)  # 转为rgb图像数组\n                img_arr = img_arr / 255.  # 数据归一化\n                x.append(img_arr.astype(np.float32))\n                y.append(i)\n                print(\"loading: \" + file)\n    x = np.array(x)\n    y = np.array(y, dtype=np.int64)\n    return x, y, x.shape[0]\n\ndef load_data():\n    print('-------------Generate Datasets-----------------')\n    x, y, xlen = readImg(root_path)\n    print(\"x: \", x.shape, \"y: \", y.shape)\n    np.random.seed(116)  # 使用相同的seed，保证输入特征和标签一一对应\n    np.random.shuffle(x)\n    np.random.seed(116)\n    np.random.shuffle(y)\n    return x, y\n\nx, y = load_data()\nsplit1 = int(0.3 * x.shape[0])\nx_val_test, y_val_test = x[:split1], y[:split1]\nx_train, y_train = x[split1:], y[split1:]\n\nsplit2 = int(0.5 * x_val_test.shape[0])\nx_test, y_test = x_val_test[:split2], y_val_test[:split2]\nx_validation, y_validation = x_val_test[split2:], y_val_test[split2:]\nprint(\"x_train: {}, y_train: {}\".format(x_train.shape, y_train.shape))\nprint(\"x_test: {}, y_test: {}\".format(x_test.shape, y_test.shape))\nprint(\"x_validation: {}, y_validation: {}\".format(x_validation.shape, y_validation.shape))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# AlexNet","metadata":{}},{"cell_type":"code","source":"class AlexNet8(Model):\n    def __init__(self):\n        super(AlexNet8, self).__init__()\n        self.c1 = Conv2D(filters=96, kernel_size=(3, 3))\n        self.b1 = BatchNormalization()\n        self.a1 = Activation('relu')\n        self.p1 = MaxPool2D(pool_size=(3, 3), strides=2)\n\n        self.c2 = Conv2D(filters=256, kernel_size=(3, 3))\n        self.b2 = BatchNormalization()\n        self.a2 = Activation('relu')\n        self.p2 = MaxPool2D(pool_size=(3, 3), strides=2)\n\n        self.c3 = Conv2D(filters=384, kernel_size=(3, 3), padding='same',\n                         activation='relu')\n                         \n        self.c4 = Conv2D(filters=384, kernel_size=(3, 3), padding='same',\n                         activation='relu')\n                         \n        self.c5 = Conv2D(filters=256, kernel_size=(3, 3), padding='same',\n                         activation='relu')\n        self.p3 = MaxPool2D(pool_size=(3, 3), strides=2)\n\n        self.flatten = Flatten()\n        self.f1 = Dense(2048, activation='relu')\n        self.d1 = Dropout(0.5)\n        self.f2 = Dense(2048, activation='relu')\n        self.d2 = Dropout(0.5)\n        self.f3 = Dense(16, activation='softmax')\n\n    def call(self, x):\n        x = self.c1(x)\n        x = self.b1(x)\n        x = self.a1(x)\n        x = self.p1(x)\n\n        x = self.c2(x)\n        x = self.b2(x)\n        x = self.a2(x)\n        x = self.p2(x)\n\n        x = self.c3(x)\n\n        x = self.c4(x)\n\n        x = self.c5(x)\n        x = self.p3(x)\n\n        x = self.flatten(x)\n        x = self.f1(x)\n        x = self.d1(x)\n        x = self.f2(x)\n        x = self.d2(x)\n        y = self.f3(x)\n        return y\n    \n    ","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 迁移学习\n## ResNet50\nResNet50(weights='imagenet', include_top=False, pooling=\"avg\") \\\nDense(16, activation=\"softmax\")","metadata":{}},{"cell_type":"code","source":"class ResNet152(Model):\n    def __init__(self):\n        super(ResNet152, self).__init__()\n        self.net = tf.keras.applications.ResNet152(\n            weights=\"imagenet\",\n            include_top=False,\n            pooling=\"avg\"\n        )\n        self.net.trainable = False\n        self.f = Dense(16, activation=\"softmax\") \n\n    def call(self, x):\n        x = self.net(x)\n        y = self.f(x)\n        return y","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 迁移学习\n## VGG19\nVGG19(weights='imagenet', include_top=False, pooling=\"max) \\\nDense(1024, activation=\"relu\") \\\nBatchNormalization() \\\nDropout(0.5) \\\nDense(16, activation=\"softmax\")","metadata":{}},{"cell_type":"code","source":"class VGG19(Model):\n    def __init__(self):\n        super(VGG19, self).__init__()\n        self.net = tf.keras.applications.VGG19(\n            weights=\"imagenet\",\n            include_top=False,\n            pooling=\"max\"\n        )\n        self.net.trainable = False\n        self.f1 = Dense(1024, activation=\"relu\")\n        self.b1 = BatchNormalization()\n        self.d1 = Dropout(0.5)\n        self.f2 = Dense(16, activation=\"softmax\") \n\n    def call(self, x):\n        x = self.net(x)\n        x = self.f1(x)\n        x = self.b1(x)\n        x = self.d1(x)\n        y = self.f2(x)\n        return y","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 迁移学习\n## InceptionV3\nInceptionV3(weights='imagenet', include_top=False, pooling=\"max) \\\nDense(1024, activation=\"relu\") \\\nBatchNormalization() \\\nDropout(0.5) \\\nDense(16, activation=\"softmax\")","metadata":{}},{"cell_type":"code","source":"class InceptionV3(Model):\n    def __init__(self):\n        super(InceptionV3, self).__init__()\n        self.net = tf.keras.applications.InceptionV3(\n            weights=\"imagenet\",\n            include_top=False,\n            pooling=\"max\"\n        )\n        self.net.trainable = False\n        self.f1 = Dense(1024, activation=\"relu\")\n        self.b1 = BatchNormalization()\n        self.d1 = Dropout(0.5)\n        self.f2 = Dense(16, activation=\"softmax\") \n\n    def call(self, x):\n        x = self.net(x)\n        x = self.f1(x)\n        x = self.b1(x)\n        x = self.d1(x)\n        y = self.f2(x)\n        return y","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 迁移学习\n## DenseNet121\nDenseNet121(weights='imagenet', include_top=False, pooling=\"max\") \\\nDense(1024, activation=\"relu\") \\\nBatchNormalization() \\\nDropout(0.5) \\\nDense(16, activation=\"softmax\")","metadata":{}},{"cell_type":"code","source":"class DenseNet121(Model):\n    def __init__(self):\n        super(DenseNet121, self).__init__()\n        self.net = tf.keras.applications.DenseNet121(\n            weights=\"imagenet\",\n            include_top=False,\n            pooling=\"max\"\n        )\n        self.net.trainable = False\n        self.f1 = Dense(1024, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2())\n        self.b1 = BatchNormalization()\n        self.d1 = Dropout(0.5)\n        self.f2 = Dense(16, activation=\"softmax\", kernel_regularizer=tf.keras.regularizers.l2()) \n\n    def call(self, x):\n        x = self.net(x)\n        x = self.f1(x)\n        x = self.b1(x)\n        x = self.d1(x)\n        y = self.f2(x)\n        return y","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MobileNetV2(Model):\n    def __init__(self):\n        super(MobileNetV2, self).__init__()\n        self.net = tf.keras.applications.MobileNetV2(\n            input_shape=(224, 224, 3),\n            weights=\"imagenet\",\n            include_top=False,\n            pooling=\"avg\"\n        )\n        self.net.trainable = False\n        self.f1 = Dense(16, activation=\"softmax\", kernel_regularizer=tf.keras.regularizers.l2()) \n\n    def call(self, x):\n        x = self.net(x)\n        y = self.f1(x)\n        return y","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# MyModel & ResNet18","metadata":{}},{"cell_type":"code","source":"class ResNet18(Model):\n\n    def __init__(self, block_list, initial_filters=64):  # block_list表示每个block有几个卷积层\n        super(ResNet18, self).__init__()\n        self.num_blocks = len(block_list)  # 共有几个block\n        self.block_list = block_list\n        self.out_filters = initial_filters\n        self.c1 = Conv2D(self.out_filters, (3, 3), strides=1, padding='same', use_bias=False)\n        self.b1 = BatchNormalization()\n        self.a1 = Activation('relu')\n        self.blocks = tf.keras.models.Sequential()\n        # 构建ResNet网络结构\n        for block_id in range(len(block_list)):  # 第几个resnet block\n            for layer_id in range(block_list[block_id]):  # 第几个卷积层\n\n                if block_id != 0 and layer_id == 0:  # 对除第一个block以外的每个block的输入进行下采样\n                    block = ResnetBlock(self.out_filters, strides=2, residual_path=True)\n                else:\n                    block = ResnetBlock(self.out_filters, residual_path=False)\n                self.blocks.add(block)  # 将构建好的block加入resnet\n            self.out_filters *= 2  # 下一个block的卷积核数是上一个block的2倍\n        self.p1 = tf.keras.layers.GlobalAveragePooling2D()\n        self.f1 = tf.keras.layers.Dense(16, activation='softmax', kernel_regularizer=tf.keras.regularizers.l2())\n\n    def call(self, inputs):\n        x = self.c1(inputs)\n        x = self.b1(x)\n        x = self.a1(x)\n        x = self.blocks(x)\n        x = self.p1(x)\n        y = self.f1(x)\n        return y\n\nclass ResnetBlock(Model):\n\n    def __init__(self, filters, strides=1, residual_path=False):\n        super(ResnetBlock, self).__init__()\n        self.filters = filters\n        self.strides = strides\n        self.residual_path = residual_path\n\n        self.c1 = Conv2D(filters, (3, 3), strides=strides, padding='same', use_bias=False)\n        self.b1 = BatchNormalization()\n        self.a1 = Activation('relu')\n\n        self.c2 = Conv2D(filters, (3, 3), strides=1, padding='same', use_bias=False)\n        self.b2 = BatchNormalization()\n\n        # residual_path为True时，对输入进行下采样，即用1x1的卷积核做卷积操作，保证x能和F(x)维度相同，顺利相加\n        if residual_path:\n            self.down_c1 = Conv2D(filters, (1, 1), strides=strides, padding='same', use_bias=False)\n            self.down_b1 = BatchNormalization()\n\n        self.a2 = Activation('relu')\n\n    def call(self, inputs):\n        residual = inputs  # residual等于输入值本身，即residual=x\n        # 将输入通过卷积、BN层、激活层，计算F(x)\n        x = self.c1(inputs)\n        x = self.b1(x)\n        x = self.a1(x)\n\n        x = self.c2(x)\n        y = self.b2(x)\n\n        if self.residual_path:\n            residual = self.down_c1(inputs)\n            residual = self.down_b1(residual)\n\n        out = self.a2(y + residual)  # 最后输出的是两部分的和，即F(x)+x或F(x)+Wx,再过激活函数\n        return out\n    \nclass Baseline(Model):\n    def __init__(self):\n        super(Baseline, self).__init__()\n        self.c1 = Conv2D(filters=32, kernel_size=(3, 3), padding='same')  # 卷积层\n        self.b1 = BatchNormalization()\n        self.a1 = Activation(\"relu\")\n        self.p1 = MaxPool2D(pool_size=(2, 2))  # 池化层\n        \n        self.c2 = Conv2D(filters=64, kernel_size=(3, 3), padding='same')  # 卷积层\n        self.b2 = BatchNormalization()\n        self.a2 = Activation(\"relu\")\n        self.p2 = MaxPool2D(pool_size=(2, 2))  # 池化层\n        \n        self.c3 = Conv2D(filters=128, kernel_size=(3, 3), padding='same')  # 卷积层\n        self.b3 = BatchNormalization()\n        self.a3 = Activation(\"relu\")\n        self.p3 = MaxPool2D(pool_size=(2, 2))  # 池化层\n        \n        self.f1 = Flatten()\n        self.f2 = Dense(128, kernel_regularizer=tf.keras.regularizers.l2())\n        self.b4 = BatchNormalization()\n        self.a4 = Activation(\"relu\")\n        self.d1 = Dropout(0.2)\n        self.f3 = Dense(32, kernel_regularizer=tf.keras.regularizers.l2()) \n        self.b5 = BatchNormalization()\n        self.a5 = Activation(\"relu\")\n        self.d2 = Dropout(0.2)\n        self.f4 = Dense(16, activation='softmax', kernel_regularizer=tf.keras.regularizers.l2())\n        \n    def call(self, x):\n        # 卷积层1\n        x = self.c1(x)\n        x = self.b1(x)\n        x = self.a1(x)\n        x = self.p1(x)\n        # 卷积层2\n        x = self.c2(x)\n        x = self.b2(x)\n        x = self.a2(x)\n        x = self.p2(x)\n        # 卷积层3\n        x = self.c3(x)\n        x = self.b3(x)\n        x = self.a3(x)\n        x = self.p3(x)\n        # 全连接层\n        x = self.f1(x)\n        x = self.f2(x)\n        x = self.b4(x)\n        x = self.a4(x)\n        x = self.d1(x)\n        x = self.f3(x)\n        x = self.b5(x)\n        x = self.a5(x)\n        x = self.d2(x)\n        y = self.f4(x)\n        return y\n    \nclass NewModel(Model):\n    def __init__(self):\n        super(NewModel, self).__init__()\n        self.c11 = Conv2D(filters=32, kernel_size=(3, 3), padding='same')  # 卷积层\n        self.c12 = Conv2D(filters=32, kernel_size=(3, 3), padding='same')  # 卷积层\n        self.c13 = Conv2D(filters=32, kernel_size=(3, 3), padding='same')  # 卷积层\n        self.b1 = BatchNormalization()\n        self.a1 = Activation(\"relu\")\n        self.p1 = MaxPool2D(pool_size=(2, 2))  # 池化层\n        self.blocks = tf.keras.models.Sequential()\n        self.block11 = ResnetBlock(filters=64, strides=2, residual_path=True)\n        self.block12 = ResnetBlock(filters=64)\n        self.block21 = ResnetBlock(filters=128, strides=2, residual_path=True)\n        self.block22 = ResnetBlock(filters=128)        \n        self.block31 = ResnetBlock(filters=256, strides=2, residual_path=True)\n        self.block32 = ResnetBlock(filters=256, strides=2, residual_path=True)\n        self.block33 = ResnetBlock(filters=256)\n        self.blocks.add(self.block11)\n        self.blocks.add(self.block12)\n        self.blocks.add(self.block21)\n        self.blocks.add(self.block22)        \n        self.blocks.add(self.block31)\n        self.blocks.add(self.block32)\n        self.blocks.add(self.block33)\n        \n        self.f1 = Flatten()\n        self.f2 = Dense(128, kernel_regularizer=tf.keras.regularizers.l2())\n        self.b2 = BatchNormalization()\n        self.a2 = Activation(\"relu\")\n        self.d1 = Dropout(0.2)\n        self.f3 = Dense(32, kernel_regularizer=tf.keras.regularizers.l2()) \n        self.b3 = BatchNormalization()\n        self.a3 = Activation(\"relu\")\n        self.d2 = Dropout(0.2)\n        self.f4 = Dense(16, activation='softmax', kernel_regularizer=tf.keras.regularizers.l2())\n        \n    def call(self, x):\n        # 卷积层1\n        x = self.c11(x)\n        x = self.c12(x)\n        x = self.c13(x)\n        x = self.b1(x)\n        x = self.a1(x)\n        x = self.p1(x)\n        # resBlock\n        x = self.blocks(x)   \n        # 全连接层\n        x = self.f1(x)\n        x = self.f2(x)\n        x = self.b2(x)\n        x = self.a2(x)\n        x = self.d1(x)\n        x = self.f3(x)\n        x = self.b3(x)\n        x = self.a3(x)\n        x = self.d2(x)\n        x = self.d1(x)\n        y = self.f4(x)\n        return y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show(history, model_name):\n    figure_save_path = \"./checkpoint/flower_\" + model_name + \".png\"\n    plt.rcParams['font.sans-serif'] = ['SimHei']\n    plt.rcParams['font.family'] = ['Times New Roman']\n    plt.rcParams['axes.unicode_minus'] = False\n\n    acc = history['sparse_categorical_accuracy']\n    val_acc = history['val_sparse_categorical_accuracy']\n    loss = history['loss']\n    val_loss = history['val_loss']\n    # print(history)\n    # 测试集结果\n    x = list(history[\"loss_test\"].keys())\n    loss_test = list(history[\"loss_test\"].values())\n    acc_test = list(history[\"acc_test\"].values())\n    print(\"lost_test\", loss_test)\n    print(\"acc_test\", acc_test)\n    epochs = len(history['loss'])\n    \n    # 作图：训练集和验证集准确率曲线图，测试集最终结果点\n    plt.figure(figsize=(12, 4)) # 画布大小12×3英寸\n    plt.subplot(1, 2, 1) # 子图1用于记录准确率\n    plt.plot(np.arange(1, epochs + 1), acc, label='train accuracy') # 绘制训练集准确率\n    plt.plot(np.arange(1, epochs + 1), val_acc, label='validation accuracy') # 绘制验证集准确率\n    plt.scatter(x, acc_test, marker=\"o\", color=\"red\") # 绘制测试集准确率散点\n    # for i, x_i in enumerate(x):\n    #     plt.plot([x_i, x_i], [0, acc_test[i]], linestyle=\"--\")\n    #     plt.plot([0, x_i], [acc_test[i], acc_test[i]], linestyle=\"--\")\n    for i, x_i in enumerate(x):  # 循环为测试集散点注解\n        plt.annotate(\"acc=%.3f\"% acc_test[i], # 注解文字\n                     xytext=(-40, -30), # 注解文字偏移\n                     xycoords=\"data\",\n                     xy=(x_i, acc_test[i]), # 注解坐标\n                     textcoords='offset points', # 注解方式\n                     arrowprops=dict(arrowstyle=\"->\", connectionstyle=\"arc3,rad=.2\")) # 注解箭头\n    plt.xlabel(\"epochs\") # x轴标签\n    plt.title('classification accuracy') # y轴标签\n    plt.legend() # 显示图注\n\n    plt.subplot(1, 2, 2) # 子图2用于记录损失函数值\n    plt.plot(np.arange(1, epochs + 1), loss, label='train loss') # 绘制训练集损失函数值\n    plt.plot(np.arange(1, epochs + 1), val_loss, label='validation loss') # 绘制验证集损失函数之\n    plt.scatter(x, loss_test, marker=\"o\", color=\"red\") # 绘制测试集损失函数值散点\n    for i, x_i in enumerate(x):  # 循环为测试集散点注解\n        plt.annotate(\"loss=%.3f\"% loss_test[i],\n                     xytext=(-50, 20),\n                     xycoords=\"data\",\n                     xy=(x_i, loss_test[i]),\n                     textcoords='offset points',\n                     arrowprops=dict(arrowstyle=\"->\", connectionstyle=\"arc3,rad=.2\"))\n    plt.xlabel(\"epochs\")\n    plt.title('loss function value')\n    plt.legend()\n\n    plt.savefig(figure_save_path) # 存储图像\n    plt.show() # 显示图像\n\ndef history_show(model_name):\n    history_save_path = \"./checkpoint/flower_\" + model_name + \"_history.pickle\"\n    history = {\"sparse_categorical_accuracy\": [],\n               \"val_sparse_categorical_accuracy\": [],\n               \"loss\": [],\n               \"val_loss\": [],\n               \"loss_test\": {},\n               \"acc_test\": {},\n               \"batch_size\": [],\n               \"lr\": []\n               }\n    count = []\n    if os.path.exists(history_save_path):\n        with open(history_save_path, 'rb') as file:\n            all_epochs = 0 # 记录历史轮次\n            while True:\n                # pickle.dump()以mode=\"ab\"模式下追加的为多个不同的pickle对象\n                # 因此需要多次dump将其多个对象加载出来\n                try:\n                    history_load = pickle.load(file) # 加载多次的历史记录\n                    # 本记录若干轮次训练集和验证集acc,loss的追加\n                    history[\"sparse_categorical_accuracy\"].extend(history_load[\"sparse_categorical_accuracy\"])\n                    history[\"val_sparse_categorical_accuracy\"].extend(history_load[\"val_sparse_categorical_accuracy\"])\n                    history[\"loss\"].extend(history_load[\"loss\"])\n                    history[\"val_loss\"].extend(history_load[\"val_loss\"])\n                    this_epoch = len(history_load[\"loss\"]) # 记录本记录的轮次\n                    count.append(this_epoch)\n                    all_epochs += this_epoch\n                    # 本记录测试集acc,loss的键值对的追加\n                    history[\"loss_test\"][all_epochs] = history_load[\"loss_test\"]\n                    history[\"acc_test\"][all_epochs] = history_load[\"acc_test\"]\n                    # 本记录批量大小和学习率的追加\n                    history[\"batch_size\"].append(history_load[\"batch_size\"])\n                    history[\"lr\"].append(history_load[\"lr\"])\n                except EOFError:\n                    train_count = len(count)\n                    print(\"总共进行\" + str(train_count) + \"次训练：\")\n                    for i in range(train_count):\n                        print(\"\"\"第{}次训练：\\n\\\n                                 \\t训练轮数为：{}轮\\n\\\n                                 \\t批量大小为：{}张图片\\n\\\n                                 \\t学习率为：{:g}\\n\n                              \"\"\".format(i + 1, count[i], history[\"batch_size\"][i], history[\"lr\"][i]))\n                    print(\"总共训练轮数：%d轮\\n\" % all_epochs)\n                    break\n    show(history, model_name)","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def model_fit_data_augment(model, epochs, x_train, y_train, x_test, y_test, x_validation, y_validation, batch_size=32, lr=0.001):\n    # 带数据增强的模型训练\n    model_name = model.__class__.__name__\n    checkpoint_save_path = \"./checkpoint/flower_\" + model_name + \".ckpt\"\n    history_save_path = \"./checkpoint/flower_\" + model_name + \"_history.pickle\"\n\n    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n                  metrics=['sparse_categorical_accuracy'])\n\n\n    if os.path.exists(checkpoint_save_path + '.index'):\n        print('-------------load the model-----------------')\n        model.load_weights(checkpoint_save_path)\n\n    cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_save_path,\n                                                     save_weights_only=True,\n                                                     save_best_only=True)\n    # 给训练集添加随机噪声\n    image_gen_train = ImageDataGenerator(\n        rescale=1. / 1.,  # 如为图像，分母为255时，可归至0～1\n        rotation_range=45,  # 随机45度旋转\n        width_shift_range=.10,  # 宽度偏移\n        height_shift_range=.10,  # 高度偏移\n        horizontal_flip=True,  # 水平翻转\n        zoom_range=0.2  # 将图像随机缩放阈量20％\n    )\n    image_gen_train.fit(x_train)\n\n    history = model.fit(image_gen_train.flow(x_train, y_train, batch_size=batch_size),\n                        # x_train, y_train, batch_size=32,\n                        epochs=epochs,\n                        verbose=1,\n                        # validation_split=0.1,\n                        validation_data=(x_validation, y_validation),\n                        validation_freq=1,\n                        callbacks=[cp_callback])\n    res = model.evaluate(x_test, y_test, verbose=1)\n    history.history[\"loss_test\"] = res[0]\n    history.history[\"acc_test\"] = res[1]\n    history.history[\"batch_size\"] = batch_size\n    history.history[\"lr\"] = lr\n    model.summary()\n\n    with open(history_save_path, 'ab') as file_pi:\n        pickle.dump(history.history, file_pi)\n\n    # show(history.history, model_name)\n\n    \ndef model_predict(model):\n    # 对传入的模型的历史数据作图，并且进行预测\n    model.compile(optimizer='adam',\n                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n                  metrics=['sparse_categorical_accuracy'])\n\n    model_name = model.__class__.__name__\n    checkpoint_save_path = \"./checkpoint/flower_\" + model_name + \".ckpt\"\n    if os.path.exists(checkpoint_save_path + '.index'):\n        print('-------------load the model-----------------')\n        model.load_weights(checkpoint_save_path)\n    else:\n        print(\"No model is chosen\")\n        exit(0)\n\n    history_show(model_name)\n\n    preNum = int(input(\"需要预测的花朵图片个数：\"))\n\n    for i in range(preNum):\n        flower = input(\"\\n类别:\")\n        flower_path = root_path + flower + \"/\"\n        flower_count = 0\n        for file in os.listdir(flower_path):\n            flower_count += 1\n        print(flower + \"类花朵共有%d张图片\" % flower_count)\n        number = input(\"序号(1~%d)：\" % flower_count)\n        image_path = flower_path + flower + \" (%s).jpg\" % number\n        img = Image.open(image_path)\n        # 展示图片\n        image = plt.imread(image_path)\n        plt.subplot(1, preNum, i + 1)\n        plt.set_cmap('gray')\n        plt.imshow(image)\n        plt.axis(\"off\")\n        img = img.convert(\"RGB\")\n        img = img.resize((224, 224), Image.ANTIALIAS)\n        img_arr = np.array(img)\n        img_arr = img_arr / 255.0\n        x = np.reshape(img_arr, (1, 224, 224, 3))\n        result = model.predict(x)\n        pred = tf.argmax(result, axis=1)\n        plt.title(flowers[int(pred.numpy())])\n    plt.suptitle(\"The model is \" + model_name)\n    plt.tight_layout()\n    plt.show()","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = AlexNet8()\nmodel_fit_data_augment(model, 100,\n         x_train, y_train, x_test, y_test, x_validation, y_validation,\n         batch_size=64, lr=0.01)","metadata":{"execution":{"iopub.status.busy":"2022-02-28T16:29:18.147991Z","iopub.execute_input":"2022-02-28T16:29:18.14841Z","iopub.status.idle":"2022-02-28T16:30:40.49891Z","shell.execute_reply.started":"2022-02-28T16:29:18.148373Z","shell.execute_reply":"2022-02-28T16:30:40.497863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_predict(model)","metadata":{"execution":{"iopub.status.busy":"2022-02-28T17:01:10.771744Z","iopub.execute_input":"2022-02-28T17:01:10.772304Z","iopub.status.idle":"2022-02-28T17:01:10.846305Z","shell.execute_reply.started":"2022-02-28T17:01:10.772214Z","shell.execute_reply":"2022-02-28T17:01:10.845476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(x_train, y_train)\nmodel.evaluate(x_validation, y_validation)\nmodel.evaluate(x_test, y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport zipfile\nimport datetime\nfrom IPython.display import FileLink\n\ndef file2zip(packagePath, zipPath):\n    '''\n  :param packagePath: 文件夹路径\n  :param zipPath: 压缩包路径\n  :return:\n  '''\n    zip = zipfile.ZipFile(zipPath, 'w', zipfile.ZIP_DEFLATED)\n    for path, dirNames, fileNames in os.walk(packagePath):\n        fpath = path.replace(packagePath, '')\n        for name in fileNames:\n            fullName = os.path.join(path, name)\n            name = fpath + '\\\\' + name\n            zip.write(fullName, name)\n    zip.close()\n\n\nif __name__ == \"__main__\":\n    # 文件夹路径\n    packagePath = '/kaggle/working/'\n    zipPath = '/kaggle/working/output.zip'\n    if os.path.exists(zipPath):\n        print(\"output.zip has already existed.\")\n        flag = input(\"Remove it or not? (Y/N)\")\n        if flag == \"Y\":\n            print(\"The old zip is removing...\")\n            os.remove(zipPath)\n            print(\"The new zip is packing...\")\n            file2zip(packagePath, zipPath)\n            print(\"Successfully!\")\n    else:\n        print(\"The zip is packing...\")\n        file2zip(packagePath, zipPath)\n        print(\"Successfully!\")\n    print(datetime.datetime.utcnow())\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"FileLink(\"output.zip\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import shutil\n# import os\n\n# if __name__ == '__main__':\n#     path = '/kaggle/working'\n#     if os.path.exists(path):\n#         shutil.rmtree(path)\n#         print('删除完成')\n#     else:\n#         print('原本为空')","metadata":{"execution":{"iopub.status.busy":"2022-02-28T16:29:09.86581Z","iopub.execute_input":"2022-02-28T16:29:09.86606Z","iopub.status.idle":"2022-02-28T16:29:10.225293Z","shell.execute_reply.started":"2022-02-28T16:29:09.866032Z","shell.execute_reply":"2022-02-28T16:29:10.220551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}